from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from sqlalchemy import create_engine
from airflow.decorators import task
from datetime import datetime, timedelta
import requests
import pandas as pd
import json
import logging
import time

default_args = {
    'owner': 'airflow',
    'start_date': datetime(2025, 6, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=3)
}

def send_slack_message(message: str):
    SLACK_URL = Variable.get("SLACK_WEBHOOK_URL")
    requests.post(SLACK_URL, json={"text": message})


@task
def make_naver_price_summary(**kwargs):
    engine = create_engine(Variable.get('POSTGRE_NAVER_CONN'))
    df_naver_price = pd.read_sql("select * from naver_price", con=engine)

    df_sorted = df_naver_price.sort_values(by=['product_id', 'dt'])
    df_sorted['prev_lprice'] = df_sorted.groupby('product_id')['lprice'].shift(1)
    df_sorted['price_change_rate'] = (df_sorted['lprice'] - df_sorted['prev_lprice']) / df_sorted['prev_lprice']
    df_sorted['price_change_rate_pct'] = df_sorted['price_change_rate'] * 100
    df_result = df_sorted.dropna(subset=['price_change_rate'])

    # product_id Î≥Ñ Î∂ÑÏÑù ÏãúÏûë
    # 1. ÏµúÍ∑º 24ÏãúÍ∞Ñ Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
    latest_dt = df_result['dt'].max()
    time_threshold = latest_dt - pd.Timedelta(hours=24)
    df_recent = df_result[df_result['dt'] > time_threshold]

    # 2. product_id, dt Ïàú Ï†ïÎ†¨
    df_recent = df_recent.sort_values(by=['product_id', 'dt'])

    # 3. Î∂ÑÏÑù Í≤∞Í≥º Ï†ÄÏû• Î¶¨Ïä§Ìä∏
    buy_signals = []

    # 4. product_id Î≥ÑÎ°ú Î∂ÑÏÑù
    for product_id, group in df_recent.groupby('product_id'):
        lprices = group['lprice'].values
        times = group['dt'].values

        if len(lprices) < 12:
            continue  # Îç∞Ïù¥ÌÑ∞Í∞Ä ÎÑàÎ¨¥ Ï†ÅÏúºÎ©¥ Ïä§ÌÇµ

        # Ïù¥Îèô ÌèâÍ∑† (ÏµúÍ∑º 12ÏãúÍ∞Ñ Í∏∞Ï§Ä)
        ma12 = pd.Series(lprices).rolling(window=12).mean().values

        # ÏãúÏûë Í∞ÄÍ≤©
        first_price = lprices[0]
        # ÌòÑÏû¨ Í∞ÄÍ≤© (Í∞ÄÏû• ÏµúÍ∑º)
        last_price = lprices[-1]
        current_time = times[-1]
        current_ma12 = ma12[-1]

        # 24ÏãúÍ∞Ñ ÏßëÍ≥Ñ
        min_price = lprices.min()
        max_price = lprices.max()
        avg_price = lprices.mean()
        price_diff = (last_price - first_price)
        price_diff_pct = price_diff / first_price * 100

        # Ï°∞Í±¥: ÌòÑÏû¨Í∞ÄÍ∞Ä MA12Î≥¥Îã§ ÎÇÆÍ≥†, ÏµúÏ†ÄÍ∞ÄÏóê Í∑ºÏ†ë (5% Ïù¥ÎÇ¥), price_diff_pct -5Ïù¥Ìïò
        if not pd.isna(
                current_ma12) and last_price < current_ma12 and last_price <= min_price * 1.05 and price_diff_pct <= -5:
            buy_signals.append({
                'product_id': product_id,
                'dt': current_time,
                'first_price': first_price,
                'last_price': last_price,
                'min_price': min_price,
                'max_price': max_price,
                'avg_price': avg_price,
                'price_diff': price_diff,
                'price_diff_pct': price_diff_pct,
            })

    if len(buy_signals) == 0:
        logging.warning("Íµ¨Îß§ÌÉÄÏù¥Î∞çÏùò Ï†úÌíàÏù¥ ÏóÜÍ±∞ÎÇò Îç∞Ïù¥ÌÑ∞Í∞Ä 12ÏãúÍ∞ÑÏù¥ÏÉÅ ÏàòÏßëÎêòÏßÄ ÏïäÏùå")
        with engine.connect() as conn:
            trans = conn.begin()  # Ìä∏ÎûúÏû≠ÏÖò ÏãúÏûë
            conn.execute("DELETE FROM summary_buy_timing")
            trans.commit()

        return

    # Í≤∞Í≥º DataFrame
    buy_df = pd.DataFrame(buy_signals)
    buy_df.set_index('product_id', inplace=True)

    # ÌïÑÏöîÌïú Ïó¥Îßå Ï∂îÏ∂ú (Ï§ëÎ≥µ Ï†úÍ±∞)
    link_title_info = df_naver_price[['product_id', 'title', 'link', 'keyword', 'keyword_type']].drop_duplicates()

    # product_idÎ•º indexÎ°ú ÏÑ§Ï†ïÌïòÏó¨ join Ï§ÄÎπÑ
    link_title_info.set_index('product_id', inplace=True)

    # filtered_dfÏóê linkÏôÄ title Î≥ëÌï©
    buy_df_with_info = buy_df.join(link_title_info, how='left')
    col_names = ['title', 'dt', 'link', 'keyword', 'keyword_type', 'first_price', 'last_price', 'min_price',
                 'max_price', 'avg_price', 'price_diff', 'price_diff_pct']
    # Í≤∞Í≥º ÌôïÏù∏
    buy_df_with_info = buy_df_with_info[col_names]


    with engine.connect() as conn:
        trans = conn.begin()  # Ìä∏ÎûúÏû≠ÏÖò ÏãúÏûë
        conn.execute("""
            CREATE TABLE IF NOT EXISTS summary_buy_timing(
                product_id bigint NOT NULL PRIMARY KEY,
                title text,
                dt timestamp,
                link text,
                keyword text,
                keyword_type text,
                first_price bigint,
                last_price bigint,
                min_price bigint,
                max_price bigint,
                avg_price double precision,
                price_diff bigint,
                price_diff_pct double precision
            )
        """)
        trans.commit()

    # ÌÖåÏù¥Î∏î full refresh
    buy_df_with_info.to_sql('summary_buy_timing', con=engine, if_exists='replace', index=True)

    # ÏÇΩÏûÖÎêòÏóàÎäîÏßÄ ÌôïÏù∏, ÎÇòÏ§ëÏóê ÏÇ≠Ï†ú
    # confirm_table = pd.read_sql("SELECT * FROM summary_buy_timing", con=engine)
    # print(confirm_table)

@task
def alert_slack_task(**kwargs):
    engine = create_engine(Variable.get('POSTGRE_NAVER_CONN'))

    df = pd.read_sql("SELECT * FROM summary_buy_timing", con=engine)

    if df.empty:
        print("‚ö†Ô∏è ÏïåÎ¶º ÎåÄÏÉÅ ÏÉÅÌíà ÏóÜÏùå.")
        return

    msgs = []
    for _, row in df.iterrows():
        max_drop = -(row['max_price'] - row['last_price'])
        max_drop_pct = -((max_drop / row['max_price']) * 100)

        msg = f"""üì¢ *[{row['title']}]*  
üîó <{row['link']}|ÏÉÅÌíà Î≥¥Îü¨Í∞ÄÍ∏∞>  
üõí ÌÇ§ÏõåÎìú: {row['keyword']} / {row['keyword_type']}  
üïò Î∂ÑÏÑù Í∏∞Ï§Ä ÏãúÏ†ê: {pd.to_datetime(row['dt']).strftime('%Y-%m-%d')}  

üí∞ ÏµúÏ¥àÍ∞Ä: {row['first_price']:,}Ïõê 
üìâ ÏµúÏ†ÄÍ∞Ä: {row['min_price']:,}Ïõê 
üìà ÏµúÍ≥†Í∞Ä: {row['max_price']:,}Ïõê
üßÆ ÌèâÍ∑†Í∞Ä: {row['avg_price']:,.2f}Ïõê  
üí∏ ÌòÑÏû¨Í∞Ä: {row['last_price']:,}Ïõê  

üîª ÏµúÏ¥àÍ∞Ä ÎåÄÎπÑ: {row['price_diff']:,}Ïõê ({row['price_diff_pct']:.2f}%)  
üîª ÏµúÍ≥†Í∞Ä ÎåÄÎπÑ: {max_drop:,}Ïõê ({max_drop_pct:.2f}%)
"""
        msgs.append(msg)

    send_slack_message('\n\n'.join(msgs))


with DAG(
        dag_id='seonghyun_summary_buy_timing',
        default_args=default_args,
        schedule_interval='5 * * * *',  # hourly
        catchup=False,
        tags=['naver', 'postgres'],
) as dag:
    # DAG Ïã§Ìñâ ÏàúÏÑú Ï†ïÏùò
    elt = make_naver_price_summary()
    alram = alert_slack_task()

    elt >> alram
